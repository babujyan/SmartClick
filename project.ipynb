{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from skimage import io \n",
    "from skimage import transform\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"test_yerevan\", exist_ok=True)\n",
    "os.makedirs(\"test_london\", exist_ok=True)\n",
    "os.makedirs(\"yerevan\", exist_ok=True)\n",
    "os.makedirs(\"london\", exist_ok=True)\n",
    "os.makedirs(\"data/train\", exist_ok=True)\n",
    "os.makedirs(\"data/valid\", exist_ok=True)\n",
    "os.makedirs(\"data/train/yerevan\", exist_ok=True)\n",
    "os.makedirs(\"data/valid/yerevan\", exist_ok=True)\n",
    "os.makedirs(\"data/train/london\", exist_ok=True)\n",
    "os.makedirs(\"data/valid/london\", exist_ok=True)\n",
    "os.makedirs(\"data/test/yerevan\", exist_ok=True)\n",
    "os.makedirs(\"data/test/london\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "yerevan = \"/test_yerevan\"\n",
    "london = \"/test_london\"\n",
    "path = os.getcwd()\n",
    "for i in range(1,7):\n",
    "    for (dirpath, dirnames, filenames) in walk(path + \"/data/\" + str(i)):\n",
    "        for file in filenames:\n",
    "            f.append((dirpath + \"/\" + file, file))\n",
    "        break\n",
    "for i in f:\n",
    "    if \"london\" in i[0]:\n",
    "        shutil.copy(i[0], path + london + \"/\" + i[1])\n",
    "    else:\n",
    "        shutil.copy(i[0], path + yerevan + \"/\" + i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(path + \"/data/test\"):\n",
    "    for file in filenames:\n",
    "        f.append((dirpath + \"/\" + file, file))\n",
    "    break\n",
    "for i in f:\n",
    "    if \"london\" in i[0]:\n",
    "        shutil.copy(i[0], path + london + \"/\" + i[1])\n",
    "    else:\n",
    "        shutil.copy(i[0], path + yerevan + \"/\" + i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizer(src, dis, size):\n",
    "    os.makedirs(dis, exist_ok=True)\n",
    "    for file in tqdm(os.listdir(src)):\n",
    "        try:\n",
    "            img = io.imread(os.path.join(src, file))\n",
    "            img = transform.resize(img, (size, size),\n",
    "                                            order=1, mode='constant',\n",
    "                                            cval=0, clip=True,\n",
    "                                            preserve_range=True,\n",
    "                                            anti_aliasing=True)\n",
    "            io.imsave(os.path.join(dis,file),img.astype(np.uint8))\n",
    "        except:\n",
    "            print(\"coudn't do it for \", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 13/70 [00:18<00:45,  1.27it/s]/home/hrach/mlpr/.venv/py3.7-mlpr/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      " 76%|███████▌  | 53/70 [01:04<00:04,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coudn't do it for  9_yerevan.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:34<00:00,  1.34s/it]\n",
      " 25%|██▌       | 19/76 [00:14<00:18,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coudn't do it for  176_london.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 27/76 [00:17<00:13,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coudn't do it for  142_london.$_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 54/76 [01:00<00:20,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coudn't do it for  158_london.-jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 58/76 [01:02<00:11,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coudn't do it for  90_london.Be\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:07<00:00,  1.68s/it]\n",
      "100%|██████████| 30/30 [00:44<00:00,  1.47s/it]\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coudn't do it for  242_yerevan.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "resizer(\"./yerevan\", \"./yerevan_resized\", 100)\n",
    "resizer(\"./london\", \"./london_resized\", 100)\n",
    "resizer(\"./test_yerevan\", \"./test_yerevan_resized\", 100)\n",
    "resizer(\"./test_london\", \"./test_london_resized\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yerevan = list(Path(\"yerevan_resized\").glob(\"*\"))\n",
    "london = list(Path(\"london_resized\").glob(\"*\"))\n",
    "test_yerevan = list(Path(\"test_yerevan_resized\").glob(\"*\"))\n",
    "test_london = list(Path(\"test_london_resized\").glob(\"*\"))\n",
    "yerevan_train, yerevan_valid = train_test_split(yerevan)\n",
    "london_train, london_valid = train_test_split(london)\n",
    "\n",
    "y_train = [0]*len(yerevan_train) + [1]*len(london_train)\n",
    "y_valid = [0]*len(yerevan_valid) + [1]*len(london_valid)\n",
    "y_test = [0]*len(test_yerevan) + [1]*len(test_london)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_(src, dist):\n",
    "    for x in src:\n",
    "        shutil.copy(str(x), os.path.join(dist, x.parts[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_(yerevan_train, \"data/train/yerevan\")\n",
    "copy_(yerevan_valid, \"data/valid/yerevan\")\n",
    "copy_(london_train, \"data/train/london\")\n",
    "copy_(london_valid, \"data/valid/london\")\n",
    "copy_(test_yerevan, \"data/test/yerevan\")\n",
    "copy_(test_london, \"data/test/london\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(100),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "data_dir = './data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNet(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(DNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(layer_sizes[0], layer_sizes[1])\n",
    "        self.layer2 = nn.Linear(layer_sizes[1], layer_sizes[2])\n",
    "        self.layer3 = nn.Linear(layer_sizes[2], layer_sizes[3])\n",
    "        self.activation1 = nn.functional.relu\n",
    "        self.activation2 = nn.functional.softmax\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation1(self.layer1(x))\n",
    "        x = self.activation1(self.layer2(x))\n",
    "        x = self.activation2(self.layer3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, dense=True):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "#                 print(inputs.shape)\n",
    "                if dense:\n",
    "                    inputs = inputs.flatten(1)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 3\n",
    "batch_count = len(y_train)//batchsize + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time, copy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = DNet([30000, 6000, 600, 2])\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/25\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrach/mlpr/.venv/py3.7-mlpr/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7073 Acc: 0.4095\n",
      "valid Loss: 0.6086 Acc: 0.7222\n",
      "\n",
      "Epoch 1/25\n",
      "----------\n",
      "train Loss: 0.6738 Acc: 0.5524\n",
      "valid Loss: 0.5486 Acc: 0.8889\n",
      "\n",
      "Epoch 2/25\n",
      "----------\n",
      "train Loss: 0.7094 Acc: 0.5143\n",
      "valid Loss: 0.5803 Acc: 0.6944\n",
      "\n",
      "Epoch 3/25\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.7048\n",
      "valid Loss: 0.5773 Acc: 0.6667\n",
      "\n",
      "Epoch 4/25\n",
      "----------\n",
      "train Loss: 0.6187 Acc: 0.7429\n",
      "valid Loss: 0.5341 Acc: 0.7222\n",
      "\n",
      "Epoch 5/25\n",
      "----------\n",
      "train Loss: 0.5917 Acc: 0.7238\n",
      "valid Loss: 0.4712 Acc: 0.8889\n",
      "\n",
      "Epoch 6/25\n",
      "----------\n",
      "train Loss: 0.6119 Acc: 0.6571\n",
      "valid Loss: 0.5020 Acc: 0.8056\n",
      "\n",
      "Epoch 7/25\n",
      "----------\n",
      "train Loss: 0.6093 Acc: 0.6952\n",
      "valid Loss: 0.4899 Acc: 0.8056\n",
      "\n",
      "Epoch 8/25\n",
      "----------\n",
      "train Loss: 0.5820 Acc: 0.7333\n",
      "valid Loss: 0.4858 Acc: 0.8056\n",
      "\n",
      "Epoch 9/25\n",
      "----------\n",
      "train Loss: 0.6001 Acc: 0.6762\n",
      "valid Loss: 0.4773 Acc: 0.8056\n",
      "\n",
      "Epoch 10/25\n",
      "----------\n",
      "train Loss: 0.5894 Acc: 0.7524\n",
      "valid Loss: 0.4889 Acc: 0.8056\n",
      "\n",
      "Epoch 11/25\n",
      "----------\n",
      "train Loss: 0.6091 Acc: 0.6952\n",
      "valid Loss: 0.4986 Acc: 0.8056\n",
      "\n",
      "Epoch 12/25\n",
      "----------\n",
      "train Loss: 0.6200 Acc: 0.6857\n",
      "valid Loss: 0.4788 Acc: 0.8056\n",
      "\n",
      "Epoch 13/25\n",
      "----------\n",
      "train Loss: 0.6025 Acc: 0.6667\n",
      "valid Loss: 0.4781 Acc: 0.8333\n",
      "\n",
      "Epoch 14/25\n",
      "----------\n",
      "train Loss: 0.6045 Acc: 0.6381\n",
      "valid Loss: 0.4774 Acc: 0.8333\n",
      "\n",
      "Epoch 15/25\n",
      "----------\n",
      "train Loss: 0.6153 Acc: 0.6476\n",
      "valid Loss: 0.4776 Acc: 0.8333\n",
      "\n",
      "Epoch 16/25\n",
      "----------\n",
      "train Loss: 0.5694 Acc: 0.7524\n",
      "valid Loss: 0.4771 Acc: 0.8333\n",
      "\n",
      "Epoch 17/25\n",
      "----------\n",
      "train Loss: 0.5847 Acc: 0.6857\n",
      "valid Loss: 0.4757 Acc: 0.8333\n",
      "\n",
      "Epoch 18/25\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.6667\n",
      "valid Loss: 0.4764 Acc: 0.8333\n",
      "\n",
      "Epoch 19/25\n",
      "----------\n",
      "train Loss: 0.5820 Acc: 0.7524\n",
      "valid Loss: 0.4762 Acc: 0.8333\n",
      "\n",
      "Epoch 20/25\n",
      "----------\n",
      "train Loss: 0.5783 Acc: 0.7143\n",
      "valid Loss: 0.4759 Acc: 0.8333\n",
      "\n",
      "Epoch 21/25\n",
      "----------\n",
      "train Loss: 0.5646 Acc: 0.7619\n",
      "valid Loss: 0.4758 Acc: 0.8333\n",
      "\n",
      "Epoch 22/25\n",
      "----------\n",
      "train Loss: 0.5951 Acc: 0.7333\n",
      "valid Loss: 0.4758 Acc: 0.8333\n",
      "\n",
      "Epoch 23/25\n",
      "----------\n",
      "train Loss: 0.6504 Acc: 0.6000\n",
      "valid Loss: 0.4758 Acc: 0.8333\n",
      "\n",
      "Epoch 24/25\n",
      "----------\n",
      "train Loss: 0.5797 Acc: 0.7238\n",
      "valid Loss: 0.4758 Acc: 0.8333\n",
      "\n",
      "Epoch 25/25\n",
      "----------\n",
      "train Loss: 0.5712 Acc: 0.7905\n",
      "valid Loss: 0.4757 Acc: 0.8333\n",
      "\n",
      "Training complete in 8m 38s\n",
      "Best valid Acc: 0.888889\n"
     ]
    }
   ],
   "source": [
    "net = train_model(net, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3904 Acc: 0.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrach/mlpr/.venv/py3.7-mlpr/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "phase =\"test\"\n",
    "\n",
    "cnet.eval()   # Set model to evaluate mode\n",
    "\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "\n",
    "# Iterate over data.\n",
    "for inputs, labels in dataloaders[phase]:\n",
    "#                 print(inputs.shape)\n",
    "#     inputs = inputs.flatten(1)\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(phase == 'train'):\n",
    "        outputs = cnet(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "    # statistics\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "loss = running_loss / dataset_sizes[phase]\n",
    "acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "    phase, loss, acc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "class CNet(Module):   \n",
    "    def __init__(self, out_channel1=4, out_channel2=4):\n",
    "        super(CNet, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, out_channel1, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(out_channel1),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(out_channel1, out_channel2, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(out_channel2),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(2500, 2)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.functional.softmax(self.linear_layers(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet=CNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrach/mlpr/.venv/py3.7-mlpr/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8020 Acc: 0.4891\n",
      "valid Loss: 0.8123 Acc: 0.5000\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.8016 Acc: 0.5109\n",
      "valid Loss: 0.8128 Acc: 0.5000\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.8017 Acc: 0.5109\n",
      "valid Loss: 0.8126 Acc: 0.5000\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.7995 Acc: 0.5109\n",
      "valid Loss: 0.8096 Acc: 0.5000\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.7584 Acc: 0.5182\n",
      "valid Loss: 0.5562 Acc: 0.7500\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6977 Acc: 0.5474\n",
      "valid Loss: 0.5422 Acc: 0.7647\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.6710 Acc: 0.5912\n",
      "valid Loss: 0.6471 Acc: 0.6029\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5839\n",
      "valid Loss: 0.5551 Acc: 0.7353\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.6204\n",
      "valid Loss: 0.4201 Acc: 0.8971\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.6134 Acc: 0.6934\n",
      "valid Loss: 0.3920 Acc: 0.8971\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.6496\n",
      "valid Loss: 0.3936 Acc: 0.9118\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.5952 Acc: 0.7153\n",
      "valid Loss: 0.3928 Acc: 0.9118\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.6276 Acc: 0.6423\n",
      "valid Loss: 0.4011 Acc: 0.9118\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.5991 Acc: 0.7007\n",
      "valid Loss: 0.3733 Acc: 0.9559\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.5757 Acc: 0.7372\n",
      "valid Loss: 0.3792 Acc: 0.9559\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.5908 Acc: 0.7153\n",
      "valid Loss: 0.3823 Acc: 0.9559\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.6204\n",
      "valid Loss: 0.3857 Acc: 0.9412\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.6079 Acc: 0.7007\n",
      "valid Loss: 0.3923 Acc: 0.9118\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.6218 Acc: 0.6350\n",
      "valid Loss: 0.3934 Acc: 0.8971\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.5995 Acc: 0.6861\n",
      "valid Loss: 0.3862 Acc: 0.9265\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.5709 Acc: 0.7372\n",
      "valid Loss: 0.3813 Acc: 0.9559\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.5943 Acc: 0.6934\n",
      "valid Loss: 0.3927 Acc: 0.9265\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.5921 Acc: 0.7007\n",
      "valid Loss: 0.3850 Acc: 0.9559\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.5992 Acc: 0.7153\n",
      "valid Loss: 0.3904 Acc: 0.9265\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.6034 Acc: 0.6715\n",
      "valid Loss: 0.3846 Acc: 0.9412\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.6121 Acc: 0.6496\n",
      "valid Loss: 0.3813 Acc: 0.9559\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.5867 Acc: 0.6861\n",
      "valid Loss: 0.3880 Acc: 0.9265\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.6100 Acc: 0.6423\n",
      "valid Loss: 0.3870 Acc: 0.9412\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.6160 Acc: 0.6934\n",
      "valid Loss: 0.3890 Acc: 0.9265\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.6142 Acc: 0.6350\n",
      "valid Loss: 0.3842 Acc: 0.9559\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.5891 Acc: 0.7007\n",
      "valid Loss: 0.3835 Acc: 0.9559\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.6021 Acc: 0.7080\n",
      "valid Loss: 0.3851 Acc: 0.9412\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.5833 Acc: 0.7080\n",
      "valid Loss: 0.3864 Acc: 0.9412\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.6252 Acc: 0.6934\n",
      "valid Loss: 0.3848 Acc: 0.9412\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.5936 Acc: 0.7153\n",
      "valid Loss: 0.3832 Acc: 0.9559\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.6496\n",
      "valid Loss: 0.3847 Acc: 0.9412\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.6239 Acc: 0.6496\n",
      "valid Loss: 0.3853 Acc: 0.9412\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.6106 Acc: 0.6861\n",
      "valid Loss: 0.3847 Acc: 0.9412\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.6430 Acc: 0.6423\n",
      "valid Loss: 0.3914 Acc: 0.9118\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.6118 Acc: 0.6715\n",
      "valid Loss: 0.3873 Acc: 0.9412\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.5924 Acc: 0.7080\n",
      "valid Loss: 0.3845 Acc: 0.9265\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.5794 Acc: 0.7518\n",
      "valid Loss: 0.3883 Acc: 0.9265\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.6039 Acc: 0.7080\n",
      "valid Loss: 0.3861 Acc: 0.9412\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.5951 Acc: 0.6569\n",
      "valid Loss: 0.3885 Acc: 0.9412\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.5708 Acc: 0.7445\n",
      "valid Loss: 0.3866 Acc: 0.9412\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.5978 Acc: 0.6861\n",
      "valid Loss: 0.3921 Acc: 0.8971\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.6038 Acc: 0.6715\n",
      "valid Loss: 0.3860 Acc: 0.9412\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.5798 Acc: 0.7372\n",
      "valid Loss: 0.3856 Acc: 0.9412\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.5973 Acc: 0.6861\n",
      "valid Loss: 0.3918 Acc: 0.9118\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.5832 Acc: 0.7080\n",
      "valid Loss: 0.3853 Acc: 0.9412\n",
      "\n",
      "Training complete in 0m 24s\n",
      "Best valid Acc: 0.955882\n"
     ]
    }
   ],
   "source": [
    "optimizer_cn = optim.SGD(cnet.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_cn, step_size=7, gamma=0.1)\n",
    "cnet=train_model(cnet, criterion, optimizer_cn, exp_lr_scheduler, 50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 100\n",
    "def data(pase):\n",
    "    data_ = []\n",
    "    path = os.getcwd()\n",
    "    for city in [\"yerevan\", \"london\"]:\n",
    "        for image in os.listdir(f'data/{pase}/{city}'): \n",
    "            path_ = os.path.join(path + f'/data/{pase}/{city}', image)\n",
    "            img = cv2.imread(path_ , cv2.IMREAD_GRAYSCALE) \n",
    "            data_.append(img.flatten() / 255)\n",
    "        if city == \"yerevan\":\n",
    "            y = np.ones(len(data_))\n",
    "    y = np.append(y, np.zeros(len(data_) - len(y)))\n",
    "    data_ = np.array(data_)\n",
    "    indices = np.arange(data_.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data_[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = data(\"train\")\n",
    "test_x, test_y = data(\"test\")\n",
    "val_x, val_y = data(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = logisticRegr.predict(val_x)\n",
    "accuracy_score(val_y, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = logisticRegr.predict(test_x)\n",
    "accuracy_score(test_y, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
